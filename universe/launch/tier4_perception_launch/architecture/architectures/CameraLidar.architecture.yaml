name: CameraLidar.architecture

depends:
  # dummy
  - LidarDummy.pipeline
  - CameraDummy.pipeline
  - MapDummy.module
  - LocalizationDummy.module
  - PlanningDummy.module

  # perception
  - ObjectSegmentation.pipeline
  - ObjectRecognitionCLMergedCenterpoint.pipeline
  - ObjectRecognitionCLMergedPointpainting.pipeline
  - ObjectRecognitionCLMergedApollo.pipeline
  - Camera2dDetection.pipeline
  - OccupancyGridMapPointcloudBased.pipeline
  - OccupancyGridMapMultiLidar.pipeline

  # parameter sets
  - TypeBeta2PerceptionCamera2dDetection.parameter_set
  - TypeBeta2PerceptionPipeline.parameter_set

modes:
  - operation:
    - mode: Runtime_mode
      description: on the vehicle
    - mode: Logging_Simulation_mode
      description: simulation mode for data log replay
  - lidar_model:
    - mode: Lidar_Centerpoint_model
      description: Lidar only model with Centerpoint detector model
    - mode: Lidar_Transfusion_model
      description: Lidar only model with Transfusion detector model
    - mode: Lidar_Apollo_model
      description: Lidar only model with Apollo detector model

components:
  - component: lidar
    element: LidarDummy.pipeline
    namespace: sensing
    compute_unit: perception_ecu_1
  - component: camera
    element: CameraDummy.pipeline
    namespace: sensing
    compute_unit: perception_ecu_1
  - component: map_loader
    element: MapDummy.module
    namespace: map
    compute_unit: dummy_ecu
  - component: localizer
    element: LocalizationDummy.module
    namespace: localization
    compute_unit: dummy_ecu

  # perception
  - component: camera_2d_detection
    element: Camera2dDetection.pipeline
    namespace: perception/object_recognition/detection
    compute_unit: perception_ecu_1
    parameter_set: TypeBeta2PerceptionCamera2dDetection.parameter_set
    
  - component: object_segmentation
    element: ObjectSegmentation.pipeline
    namespace: perception
    compute_unit: main_ecu
    parameter_set: TypeBeta2PerceptionPipeline.parameter_set

  - component: object_recognition
    element: ObjectRecognitionCLMergedCenterpoint.pipeline
    namespace: perception
    compute_unit: main_ecu
    parameter_set: TypeBeta2PerceptionPipeline.parameter_set
    modes:
      - lidar_model: [Lidar_Centerpoint_model]
      - operation: [Runtime_mode, Logging_Simulation_mode]
  - component: object_recognition
    element: ObjectRecognitionCLMergedPointpainting.pipeline
    namespace: perception
    compute_unit: main_ecu
    parameter_set: TypeBeta2PerceptionPipeline.parameter_set
    modes:
      - lidar_model: [Lidar_Pointpainting_model]
      - operation: [Runtime_mode, Logging_Simulation_mode]
  - component: object_recognition
    element: ObjectRecognitionCLMergedApollo.pipeline
    namespace: perception
    compute_unit: main_ecu
    parameter_set: TypeBeta2PerceptionPipeline.parameter_set
    modes:
      - lidar_model: [Lidar_Apollo_model]
      - operation: [Runtime_mode, Logging_Simulation_mode]

  # - component: occupancy_grid_map
  #   element: OccupancyGridMapPointcloudBased.pipeline
  #   namespace: perception
  #   compute_unit: main_ecu
  - component: occupancy_grid_map
    element: OccupancyGridMapMultiLidar.pipeline
    namespace: perception
    compute_unit: main_ecu

  # planner
  - component: planner
    element: PlanningDummy.module
    namespace: planning
    compute_unit: dummy_ecu

connections:
  - from: lidar.output.concatenated/pointcloud
    to: object_recognition.input.concatenated_pointcloud
  - from: lidar.output.concatenated/pointcloud
    to: object_segmentation.input.concatenated_pointcloud
  - from: object_segmentation.output.pointcloud
    to: object_recognition.input.obstacle_pointcloud

  - from: camera.output.camera*/image
    to: camera_2d_detection.input.image_raw*
  - from: camera_2d_detection.output.rois*
    to: object_recognition.input.rois*
  - from: camera.output.camera*/camera_info
    to: object_recognition.input.camera_info*

  # - from: lidar.output.concatenated/pointcloud
  #   to: occupancy_grid_map.input.concatenated_pointcloud
  # - from: object_segmentation.output.pointcloud
  #   to: occupancy_grid_map.input.obstacle_pointcloud
  # - from: occupancy_grid_map.output.map
  #   to: planner.input.occupancy_grid_map

  - from: object_segmentation.output.pointcloud
    to: occupancy_grid_map.input.obstacle_pointcloud
  - from: lidar.output.top/pointcloud
    to: occupancy_grid_map.input.pointcloud_1
  - from: lidar.output.left/pointcloud
    to: occupancy_grid_map.input.pointcloud_2
  - from: lidar.output.right/pointcloud
    to: occupancy_grid_map.input.pointcloud_3
  - from: occupancy_grid_map.output.map
    to: planner.input.occupancy_grid_map

  - from: map_loader.output.vector_map
    to: localizer.input.lanelet_map
  - from: map_loader.output.vector_map
    to: object_recognition.input.vector_map
  - from: map_loader.output.vector_map
    to: planner.input.lanelet_map
  - from: map_loader.output.pointcloud_map
    to: object_recognition.input.pointcloud_map
  - from: object_recognition.output.objects
    to: planner.input.predicted_objects
